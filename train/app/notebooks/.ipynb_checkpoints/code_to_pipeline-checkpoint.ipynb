{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "99db660a-119b-4720-b7db-7e3ebbb80d80",
    "_execution_state": "idle",
    "_uuid": "d390300d4c49a69634911ae2f56d770cac96c232"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a hacer nuestro propio split para tener la Y en el test set y poder obtener el score sobre el test set, ademas de poder comprobar si nos estaria haciendo overfitting por ejemplo\n",
    "df    = pd.read_csv(\"../data/data.csv\")\n",
    "titanic_df, test_df = train_test_split(df, test_size=0.2, random_state=50,stratify=df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# primero eliminamos todas las columnas que no queremos\n",
    "class eliminaColumnas(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols_to_remove=None):\n",
    "        self.cols_to_remove = cols_to_remove\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        _X.drop(self.cols_to_remove, axis=1,inplace=True)\n",
    "        \n",
    "        return _X\n",
    "\n",
    "    \n",
    "class customPipeline(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init(self):\n",
    "        self.train_cols_dummies = None\n",
    "        self.target_col = \"Survived\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # solo se llama para el train\n",
    "        \n",
    "        # entonces hacemos el dummies aqui que seria para el train\n",
    "        print('<fit>------> dummies')\n",
    "        X = pd.get_dummies(X)\n",
    "        self.train_cols_dummies = X.columns\n",
    "        \n",
    "        # guardamos las columnas a la nube\n",
    "        print('<fit>------> Saving encoded columns')\n",
    "        #cos.save_object_in_cos(X.columns, 'encoded_columns', timestamp)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if self.train_cols_dummies is not None:\n",
    "            # no estamos en train\n",
    "            # hacemos dummies y comparamos las columnas con las de train\n",
    "            print('<transform>------> test dummies')\n",
    "            X = pd.get_dummies(X)\n",
    "            \n",
    "            # mismas cols que en train\n",
    "            print('<transform>------> test igualamos columnas')\n",
    "            X = X.reindex(labels = self.train_cols_dummies, axis = 1, fill_value = 0)    \n",
    "\n",
    "        # creaciÃ³n de variable Child de tipo booleana\n",
    "        print('------> Creating child')\n",
    "        X['Child'] = 0\n",
    "        X.loc[X.Age < 16, 'Child'] = 1\n",
    "        \n",
    "        return X\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "20d906f4-4450-4037-b466-d3d31da10479",
    "_uuid": "01285817befba9347f29c4f5912b62f53367233a"
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "\n",
    "X_train = titanic_df.drop(\"Survived\",axis=1)\n",
    "Y_train = titanic_df[\"Survived\"]\n",
    "\n",
    "X_test  = test_df.drop([\"Survived\"],axis=1).copy()\n",
    "Y_test = test_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "27476379-e949-4480-a282-8138c8f04580",
    "_uuid": "9bc380c6ccbed68592e8e708c9fb45c14915680a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fit>------> dummies\n",
      "<fit>------> Saving encoded columns\n",
      "<transform>------> test dummies\n",
      "<transform>------> test igualamos columnas\n",
      "------> Creating child\n",
      "<transform>------> test dummies\n",
      "<transform>------> test igualamos columnas\n",
      "------> Creating child\n",
      "Test set score: 0.8659217877094972\n",
      "<transform>------> test dummies\n",
      "<transform>------> test igualamos columnas\n",
      "------> Creating child\n",
      "[0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17731/3182078513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m '''\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "rfPipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"eliminaColumnas\",eliminaColumnas(['PassengerId','Name','Ticket'])),\n",
    "        (\"customPipeline\",customPipeline()),\n",
    "        (\"simpleimputer\",SimpleImputer(strategy = 'median', fill_value = 0)),\n",
    "        (\"model\",RandomForestClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "rfPipeline.fit(X_train, Y_train)\n",
    "\n",
    "random_forest_score = rfPipeline.score(X_test,Y_test)\n",
    "print('Test set score: ' + str(random_forest_score))\n",
    "\n",
    "\n",
    "nuevo_df =  pd.read_csv(\"/home/natxo-casa/Desktop/teno/prueba.csv\")\n",
    "print(rfPipeline.predict(nuevo_df))\n",
    "\n",
    "\n",
    "print(rfPipeline.named_steps[\"model\"].feature_importances_)\n",
    "\n",
    "'''\n",
    "#cv params\n",
    "parameters = { \n",
    "    'model__n_estimators': [200, 500],\n",
    "    'model__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'model__max_depth' : [4,5,6,7,8],\n",
    "    'model__criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf_version = GridSearchCV(rfPipeline, parameters, n_jobs=-1)\n",
    "rf_version.fit(X_train, Y_train)\n",
    "random_forest_score = rf_version.score(X_test,Y_test)\n",
    "\n",
    "print('Training set score: ' + str(rf_version.score(X_train,Y_train)))\n",
    "print('Test set score: ' + str(random_forest_score))\n",
    "print('GridSearchCV params: ', rf_version.best_params_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1171de5606304c263250778f772ccc7a83c1fb4b34f78a70a71b842915d15b9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
